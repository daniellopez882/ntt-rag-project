# Agentic RAG Project

A modern Agentic RAG (Retrieval-Augmented Generation) system built with Pydantic AI, FastAPI, and PostgreSQL (pgvector). This project provides a scalable, modular, and production-ready foundation for document-based AI applications.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Tech Stack](#tech-stack)
- [Installation](#installation)
- [Usage](#usage)
- [API Reference](#api-reference)
- [Project Structure](#project-structure)
- [License](#license)

## âœ¨ Features

- ğŸ§  Pydantic AI-based intelligent agent system
- ğŸ” Multiple search strategies: Vector Search and Hybrid Search
- ğŸ“„ Advanced PDF processing: Table and image extraction with Docling
- ğŸ’¾ Database: PostgreSQL + pgvector extension
- ğŸŒŠ Real-time streaming: Live responses via Server-Sent Events
- ğŸ¯ Session management: Conversation history and context retention
- ğŸ³ Docker containerization: Easy deployment
- ğŸ”§ Type safety: Reliable data handling with Pydantic models
- âš¡ Instant ingestion: Upload documents and query immediately

## ğŸ› ï¸ Tech Stack

### Backend

- [Pydantic AI](https://ai.pydantic.dev/) - AI Agent Framework
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [LangChain](https://langchain.readthedocs.io/) - Document processing and embeddings
- [Docling](https://github.com/DS4SD/docling) - PDF extraction and analysis
- [AsyncPG](https://magicstack.github.io/asyncpg/) - PostgreSQL async client
- [pgvector](https://github.com/pgvector/pgvector) - Vector similarity search

### Frontend

- [Streamlit](https://streamlit.io/) - Interactive web interface

### Infrastructure

- [PostgreSQL 17](https://www.postgresql.org/) - Primary database
- [Docker Compose](https://docs.docker.com/compose/) - Multi-container deployment
- [uv](https://github.com/astral-sh/uv) - Fast Python package installer

## ğŸš€ Installation

### Prerequisites

- Python 3.12+
- Docker & Docker Compose
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/daniellopez882/ntt-rag-project.git
cd ntt-rag-project
```

### 2. Set Up Environment Variables

Create a `.env` file from `.env.example`:

```bash
# API Configuration
APP_ENV=development
LOG_LEVEL=INFO
APP_HOST=0.0.0.0
APP_PORT=8058
API_URL=http://api:8058

# Streamlit Configuration
SERVER_PORT=8501
SERVER_HOST=0.0.0.0

# PostgreSQL Vector DB Configuration
DB_USER=postgres
DB_PASSWORD=postgres
DB_HOST=postgres
DB_PORT=5432
DB_NAME=vector_db

# OpenAI API Configuration (required)
OPENAI_API_KEY=your_openai_api_key
LLM_CHOICE=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small
```

### 3. Start with Docker

```bash
docker-compose up -d
docker-compose logs -f
```

## ğŸ“š Usage

### Web Interface

Access the Streamlit UI: <http://localhost:8501>

### API Usage

FastAPI documentation: <http://localhost:8058/docs>

## ğŸ—ï¸ Project Structure

```text
ntt_rag_project/
â”œâ”€â”€ agent/                  # AI Agent and business logic
â”‚   â”œâ”€â”€ agent.py           # Main Pydantic AI agent
â”‚   â”œâ”€â”€ api.py             # FastAPI endpoints
â”‚   â”œâ”€â”€ db_utils.py        # Database operations
â”‚   â”œâ”€â”€ models.py          # Pydantic models
â”‚   â”œâ”€â”€ prompts.py         # System prompts
â”‚   â”œâ”€â”€ providers.py       # LLM and embedding providers
â”‚   â””â”€â”€ tools.py           # Agent tools
â”œâ”€â”€ ingestion/             # Document processing
â”‚   â”œâ”€â”€ chunker.py         # Text chunking
â”‚   â”œâ”€â”€ extract_files.py   # PDF extraction
â”‚   â””â”€â”€ ingest.py          # Main ingestion pipeline
â”œâ”€â”€ ui/                    # Streamlit UI
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ sql/                   # Database schema
â”‚   â””â”€â”€ schema.sql
â”œâ”€â”€ docker-compose.yml     # Container orchestration
â”œâ”€â”€ Dockerfile
â””â”€â”€ pyproject.toml         # Python dependencies
```

## ğŸ“„ License

Apache2.0 License - See `LICENCE` for details.

---

Author: daniellopez882
